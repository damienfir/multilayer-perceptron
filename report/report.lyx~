#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_amsmath 1
\use_esint 1
\use_mhchem 1
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Project Report
\end_layout

\begin_layout Author
Nicolas Voirol, Damien Firmenich
\begin_inset Newline newline
\end_inset

EPFL, School of Computer and Communication Sciences
\end_layout

\begin_layout Date
Spring 2013
\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Standard
Pattern classification and machine learning provide us with a large set
 of powerful tools and techniques.
 The sheer number and the diversity of these tools can make selecting the
 ideal technique for a given problem quite difficult.
 We could simply decide we want to use the best techniques available to
 make sure our system is optimal, but with complexity comes time consumption.
 Therefore, when using an elaborate tool to solve a classification problem,
 it is generally useful to make sure it actually performs better than a
 simpler technique.
 This project compares the Multi Layer Preceptron technique against Least
 Squares Estimation and Logistic Regression on the NORB dataset.
\end_layout

\begin_layout Section*
Methods
\end_layout

\begin_layout Standard
The theory places gradient descent in batch mode above stochastic online
 descent in terms of the optimality of each update.
 We therefore implemented partial (or mini) batch mode with varying batch
 size to compare their actual impact on convergence speed and final error
 rate.
 We implemented this feature in our MLP and Logistic Regression classifiers
 since they are both based on gradient descent.
\end_layout

\begin_layout Subsection*
Preprocessing
\end_layout

\begin_layout Subsection*
Model and parameters
\end_layout

\begin_layout Paragraph*
Binary MLP
\end_layout

\begin_layout Paragraph*
Logistic Regression
\end_layout

\begin_layout Standard
The Logistic Regression technique doesn't have any model parameters, but
 it relies on gradient descent which does (namely the learning rate 
\begin_inset Formula $\eta$
\end_inset

, momentum term 
\begin_inset Formula $\mu$
\end_inset

, and the mini-batch size).
 Unfortunately, as in the MLP case, it is difficult to perform standard
 model selection on these parameters.
\end_layout

\begin_layout Standard
After having manually determined plausible parameter combinations, we performed
 model selection by comparing convergence speed and final error rate, resulting
 in an optimal strategy of ...
\end_layout

\begin_layout Paragraph*
Least Squares Estimation
\end_layout

\begin_layout Standard
The analytical solution to the Least Squares Estimation with Tikhonov Regulariza
tion problem is obtained by solving the normal equations problem.
 In the case of multi-way classification, the solution is trivially extended
 by solving the equations for each of the k vectors obtained by using 
\emph on
1 of K
\emph default
 encoding for the target vector 
\series bold
\emph on
t
\series default
\emph default
.
 But this also means we multiply the impact of the Tikhonov regularizer
 by k.
 To compensate for this, we modified the regularized error function slightly
 : 
\begin_inset Formula 
\[
E(\mathbf{W})=\frac{1}{2}\sum_{i=1}^{N}\parallel\mathbf{y}(\mathbf{x}_{i})-\mathbf{\tilde{t}}_{i}\parallel^{2}+\frac{1}{k}\frac{\nu}{2}\sum_{k=1}^{K}\parallel\mathbf{w}_{k}\parallel^{2}
\]

\end_inset


\end_layout

\begin_layout Standard
The model selection process for the Least Squares Estimation technique was
 by far the simplest since we were dealing with a single parameter and a
 constant convergence time.
 We initially got a feeling for plausible values by setting the Tikhonov
 regularizer to the exponential range 
\begin_inset Formula $\left\{ 0\right\} \cup\left\{ 0.05*\sum_{k=0}^{9}2^{k}\right\} $
\end_inset

 (see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:lstsq_interval"

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename lstsq_interval.pdf
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Interval selection for Tikhonov regularization parameter computed by performing
 10-fold cross-validation.
\begin_inset CommandInset label
LatexCommand label
name "fig:lstsq_interval"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Once we had singled out a suitable interval, namely 
\begin_inset Formula $\left[0;1.2\right]$
\end_inset

, we performed a more precise search by resorting to a linear parameter
 space of 
\begin_inset Formula $\left\{ 0.05*x\mid x\in\mathbb{N\wedge}0\leq x<25\right\} $
\end_inset

 (see Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:lstsq_errors"

\end_inset

) and we can thus place the optimal regularizer at 
\begin_inset ERT
status open

\begin_layout Plain Layout

$v = 0.6$
\end_layout

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename lstsq_errors.pdf
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:tikhonov_a"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename lstsq_classerrors.pdf
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "fig:tikhonov_b"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Error function value (
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:tikhonov_a"

\end_inset

) and classification error rate (
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:tikhonov_b"

\end_inset

) during parameter selection for Tikhonov regularizer computed as during
 interval selection.
 We can clearly see the curve minimum around 0.5 (the actual minimum is at
 0.6).
\begin_inset CommandInset label
LatexCommand label
name "fig:lstsq_errors"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Paragraph
Mutli-way MLP
\end_layout

\begin_layout Section*
Results and Discussion
\end_layout

\begin_layout Paragraph*
Binary MLP
\end_layout

\begin_layout Paragraph*
Logistic Regression
\end_layout

\begin_layout Paragraph*
Least Squares Estimation
\end_layout

\begin_layout Paragraph
Mutli-way MLP
\end_layout

\end_body
\end_document
